#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
æµ‹è¯•çˆ¬å–åŠŸèƒ½å’ŒAIæ€»ç»“åŠŸèƒ½
æ­¤è„šæœ¬ç”¨äºéªŒè¯ä¿®å¤åçš„crawlæ¥å£æ˜¯å¦èƒ½æ­£ç¡®çˆ¬å–ç½‘é¡µå†…å®¹å¹¶åœ¨å¯ç”¨AIæ—¶ç”Ÿæˆæ€»ç»“
"""

import requests
import time
import json
import logging
import os

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# æœåŠ¡å™¨åŸºç¡€URL
BASE_URL = "http://127.0.0.1:5000"

# æµ‹è¯•çš„URLåˆ—è¡¨ï¼ˆä½¿ç”¨ä¸€äº›å¸¸è§çš„å¯çˆ¬å–ç½‘ç«™æˆ–æœ¬åœ°æµ‹è¯•ç½‘ç«™ï¼‰
TEST_URLS = [
    "http://example.com",  # ç»å…¸æµ‹è¯•ç½‘ç«™ï¼Œå…è®¸çˆ¬è™«
    "https://httpbin.org/html",  # æä¾›æµ‹è¯•HTMLå†…å®¹çš„ç½‘ç«™
]

# æµ‹è¯•æ·±åº¦
TEST_DEPTH = 1


def test_crawl_without_ai(url):
    """æµ‹è¯•ä¸å¸¦AIæ€»ç»“çš„çˆ¬å–åŠŸèƒ½"""
    logger.info(f"å¼€å§‹æµ‹è¯•ä¸å¸¦AIçš„çˆ¬å–åŠŸèƒ½: {url}")
    
    endpoint = f"{BASE_URL}/api/crawl"
    payload = {
        "url": url,
        "depth": TEST_DEPTH,
        "use_ai": False
    }
    
    try:
        # å‘é€è¯·æ±‚å¹¶è®°å½•æ—¶é—´
        start_time = time.time()
        response = requests.post(endpoint, json=payload, timeout=60)
        end_time = time.time()
        
        # æ£€æŸ¥å“åº”çŠ¶æ€
        if response.status_code != 200:
            logger.error(f"çˆ¬å–è¯·æ±‚å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}")
            return False
        
        # è§£æå“åº”å†…å®¹
        result = response.json()
        
        # æ‰“å°å“åº”å†…å®¹ä»¥è°ƒè¯•
        logger.debug(f"çˆ¬å–å“åº”: {json.dumps(result, ensure_ascii=False, indent=2)}")
        
        # æ£€æŸ¥å“åº”ç»“æ„
        if "status" not in result or result["status"] != "success":
            logger.error(f"å“åº”çŠ¶æ€é”™è¯¯: {result}")
            return False
        
        # è·å–æ•°æ®éƒ¨åˆ†
        data = result.get("data", {})
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯æ¨¡æ‹Ÿç»“æœ
        is_mock = data.get("is_mock", True)
        logger.info(f"æ˜¯å¦ä¸ºæ¨¡æ‹Ÿç»“æœ: {is_mock}")
        
        # æ£€æŸ¥çˆ¬å–ç»“æœæ˜¯å¦åŒ…å«é¡µé¢ä¿¡æ¯
        if is_mock:
            # å¦‚æœæ˜¯æ¨¡æ‹Ÿç»“æœï¼Œæ£€æŸ¥åŸºæœ¬å­—æ®µ
            if "content" not in data:
                logger.error("æ¨¡æ‹Ÿç»“æœä¸­ç¼ºå°‘contentå­—æ®µ")
                return False
            if "images" not in data:
                logger.error("æ¨¡æ‹Ÿç»“æœä¸­ç¼ºå°‘imageså­—æ®µ")
                return False
            if "links" not in data:
                logger.error("æ¨¡æ‹Ÿç»“æœä¸­ç¼ºå°‘linkså­—æ®µ")
                return False
            
            logger.info(f"æ¨¡æ‹Ÿç»“æœæµ‹è¯•é€šè¿‡ï¼Œå†…å®¹é•¿åº¦: {len(data['content'])}")
            logger.info(f"æ¨¡æ‹Ÿå›¾ç‰‡æ•°é‡: {len(data['images'])}")
            logger.info(f"æ¨¡æ‹Ÿé“¾æ¥æ•°é‡: {len(data['links'])}")
        else:
            # å¦‚æœæ˜¯çœŸå®ç»“æœï¼Œæ£€æŸ¥pageså­—æ®µå’Œè¯¦ç»†ä¿¡æ¯
            if "pages" not in data or not isinstance(data["pages"], list):
                logger.error("çœŸå®ç»“æœä¸­ç¼ºå°‘pageså­—æ®µ")
                return False
            
            if len(data["pages"]) == 0:
                logger.warning("çˆ¬å–ç»“æœä¸­æ²¡æœ‰é¡µé¢æ•°æ®")
                # å¦‚æœæ²¡æœ‰é¡µé¢æ•°æ®ï¼Œæ£€æŸ¥æ˜¯å¦æœ‰æç¤ºä¿¡æ¯
                if "message" in data:
                    logger.info(f"æç¤ºä¿¡æ¯: {data['message']}")
            else:
                # æ£€æŸ¥ç¬¬ä¸€ä¸ªé¡µé¢çš„è¯¦ç»†ä¿¡æ¯
                first_page = data["pages"][0]
                page_url = first_page.get("url", "")
                
                # æ£€æŸ¥é¡µé¢åŸºæœ¬ä¿¡æ¯
                required_fields = ["title", "text", "images", "links"]
                missing_fields = [field for field in required_fields if field not in first_page]
                
                if missing_fields:
                    logger.error(f"é¡µé¢ä¿¡æ¯ç¼ºå°‘å­—æ®µ: {missing_fields}")
                    return False
                
                logger.info(f"æˆåŠŸçˆ¬å–é¡µé¢: {page_url}")
                logger.info(f"é¡µé¢æ ‡é¢˜: {first_page['title']}")
                logger.info(f"æ–‡æœ¬é•¿åº¦: {len(first_page['text'])}")
                logger.info(f"å›¾ç‰‡æ•°é‡: {len(first_page['images'])}")
                logger.info(f"é“¾æ¥æ•°é‡: {len(first_page['links'])}")
        
        # æ£€æŸ¥ç»Ÿè®¡ä¿¡æ¯
        if "stats" in data:
            stats = data["stats"]
            logger.info(f"çˆ¬å–ç»Ÿè®¡: æˆåŠŸ {stats.get('success_count', 0)}, å¤±è´¥ {stats.get('error_count', 0)}")
        
        # è®°å½•è¯·æ±‚è€—æ—¶
        logger.info(f"çˆ¬å–è¯·æ±‚è€—æ—¶: {end_time - start_time:.2f}ç§’")
        
        return True
        
    except requests.exceptions.Timeout:
        logger.error("çˆ¬å–è¯·æ±‚è¶…æ—¶")
        return False
    except requests.exceptions.ConnectionError:
        logger.error("è¿æ¥æœåŠ¡å™¨å¤±è´¥ï¼Œè¯·ç¡®ä¿æœåŠ¡å™¨æ­£åœ¨è¿è¡Œ")
        return False
    except Exception as e:
        logger.error(f"çˆ¬å–æµ‹è¯•è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}")
        return False


def test_crawl_with_ai(url):
    """æµ‹è¯•å¸¦AIæ€»ç»“çš„çˆ¬å–åŠŸèƒ½"""
    logger.info(f"å¼€å§‹æµ‹è¯•å¸¦AIçš„çˆ¬å–åŠŸèƒ½: {url}")
    
    endpoint = f"{BASE_URL}/api/crawl"
    payload = {
        "url": url,
        "depth": TEST_DEPTH,
        "use_ai": True
    }
    
    try:
        # å‘é€è¯·æ±‚å¹¶è®°å½•æ—¶é—´
        start_time = time.time()
        response = requests.post(endpoint, json=payload, timeout=120)  # å¸¦AIçš„è¯·æ±‚å¯èƒ½éœ€è¦æ›´é•¿æ—¶é—´
        end_time = time.time()
        
        # æ£€æŸ¥å“åº”çŠ¶æ€
        if response.status_code != 200:
            logger.error(f"å¸¦AIçš„çˆ¬å–è¯·æ±‚å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}")
            return False
        
        # è§£æå“åº”å†…å®¹
        result = response.json()
        
        # æ‰“å°å“åº”å†…å®¹ä»¥è°ƒè¯•
        logger.debug(f"å¸¦AIçš„çˆ¬å–å“åº”: {json.dumps(result, ensure_ascii=False, indent=2)}")
        
        # æ£€æŸ¥å“åº”ç»“æ„
        if "status" not in result or result["status"] != "success":
            logger.error(f"å“åº”çŠ¶æ€é”™è¯¯: {result}")
            return False
        
        # è·å–æ•°æ®éƒ¨åˆ†
        data = result.get("data", {})
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯æ¨¡æ‹Ÿç»“æœ
        is_mock = data.get("is_mock", True)
        logger.info(f"æ˜¯å¦ä¸ºæ¨¡æ‹Ÿç»“æœ: {is_mock}")
        
        # æ£€æŸ¥AIæ€»ç»“åŠŸèƒ½
        ai_summary_found = False
        
        if is_mock:
            # å¦‚æœæ˜¯æ¨¡æ‹Ÿç»“æœï¼Œæ£€æŸ¥summaryå­—æ®µ
            if "summary" not in data:
                logger.error("æ¨¡æ‹Ÿç»“æœä¸­ç¼ºå°‘summaryå­—æ®µ")
                return False
            
            logger.info(f"æ¨¡æ‹ŸAIæ€»ç»“: {data['summary']}")
            ai_summary_found = True
        else:
            # å¦‚æœæ˜¯çœŸå®ç»“æœï¼Œæ£€æŸ¥æ¯ä¸ªé¡µé¢çš„summaryå­—æ®µ
            if "pages" not in data or not isinstance(data["pages"], list):
                logger.error("çœŸå®ç»“æœä¸­ç¼ºå°‘pageså­—æ®µ")
                return False
            
            for page in data["pages"]:
                if "summary" in page:
                    logger.info(f"é¡µé¢ {page.get('url', 'unknown')} çš„AIæ€»ç»“é•¿åº¦: {len(page['summary'])}")
                    ai_summary_found = True
                    
                    # æ£€æŸ¥æ€»ç»“ç»Ÿè®¡ä¿¡æ¯
                    if "summary_stats" in page:
                        stats = page["summary_stats"]
                        logger.info(f"æ€»ç»“ç»Ÿè®¡: åŸæ–‡é•¿åº¦ {stats.get('original_length', 0)}, æ€»ç»“é•¿åº¦ {stats.get('summary_length', 0)}")
                    
                    # åªæ˜¾ç¤ºç¬¬ä¸€ä¸ªé¡µé¢çš„æ€»ç»“å†…å®¹
                    if len(page['summary']) > 100:
                        logger.info(f"æ€»ç»“å†…å®¹é¢„è§ˆ: {page['summary'][:100]}...")
                    else:
                        logger.info(f"æ€»ç»“å†…å®¹: {page['summary']}")
                    
                    break  # åªæ£€æŸ¥ç¬¬ä¸€ä¸ªé¡µé¢çš„æ€»ç»“
        
        # éªŒè¯æ˜¯å¦æ‰¾åˆ°äº†AIæ€»ç»“
        if not ai_summary_found:
            logger.error("æœªæ‰¾åˆ°AIæ€»ç»“ç»“æœ")
            return False
        
        # è®°å½•è¯·æ±‚è€—æ—¶
        logger.info(f"å¸¦AIçš„çˆ¬å–è¯·æ±‚è€—æ—¶: {end_time - start_time:.2f}ç§’")
        
        return True
        
    except requests.exceptions.Timeout:
        logger.error("å¸¦AIçš„çˆ¬å–è¯·æ±‚è¶…æ—¶")
        return False
    except requests.exceptions.ConnectionError:
        logger.error("è¿æ¥æœåŠ¡å™¨å¤±è´¥ï¼Œè¯·ç¡®ä¿æœåŠ¡å™¨æ­£åœ¨è¿è¡Œ")
        return False
    except Exception as e:
        logger.error(f"å¸¦AIçš„çˆ¬å–æµ‹è¯•è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}")
        return False


def run_all_tests():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    logger.info("======= å¼€å§‹çˆ¬å–åŠŸèƒ½å’ŒAIæ€»ç»“åŠŸèƒ½æµ‹è¯• =======")
    
    # æ£€æŸ¥æœåŠ¡å™¨æ˜¯å¦æ­£åœ¨è¿è¡Œ
    try:
        response = requests.get(f"{BASE_URL}/api/ping", timeout=5)
        if response.status_code != 200:
            logger.error("æœåŠ¡å™¨æœªæ­£å¸¸è¿è¡Œ")
            logger.info("è¯·å…ˆå¯åŠ¨æœåŠ¡å™¨: python server/server.py")
            return
    except requests.exceptions.ConnectionError:
        logger.error("æ— æ³•è¿æ¥åˆ°æœåŠ¡å™¨")
        logger.info("è¯·å…ˆå¯åŠ¨æœåŠ¡å™¨: python server/server.py")
        return
    
    # åˆå§‹åŒ–æµ‹è¯•ç»“æœ
    results = {
        "total": 0,
        "passed": 0,
        "failed": 0
    }
    
    # å¯¹æ¯ä¸ªURLè¿è¡Œæµ‹è¯•
    for url in TEST_URLS:
        # æµ‹è¯•ä¸å¸¦AIçš„çˆ¬å–
        results["total"] += 1
        logger.info(f"\n--- æµ‹è¯• {results['total']}: ä¸å¸¦AIçˆ¬å– {url} ---")
        if test_crawl_without_ai(url):
            results["passed"] += 1
            logger.info("âœ… æµ‹è¯•é€šè¿‡")
        else:
            results["failed"] += 1
            logger.info("âŒ æµ‹è¯•å¤±è´¥")
        
        # æµ‹è¯•å¸¦AIçš„çˆ¬å–
        results["total"] += 1
        logger.info(f"\n--- æµ‹è¯• {results['total']}: å¸¦AIçˆ¬å– {url} ---")
        if test_crawl_with_ai(url):
            results["passed"] += 1
            logger.info("âœ… æµ‹è¯•é€šè¿‡")
        else:
            results["failed"] += 1
            logger.info("âŒ æµ‹è¯•å¤±è´¥")
        
        # åœ¨ä¸¤æ¬¡æµ‹è¯•ä¹‹é—´æ·»åŠ çŸ­æš‚å»¶è¿Ÿ
        time.sleep(2)
    
    # æ‰“å°æµ‹è¯•æ€»ç»“
    logger.info("\n======= æµ‹è¯•æ€»ç»“ =======")
    logger.info(f"æ€»æµ‹è¯•æ•°: {results['total']}")
    logger.info(f"é€šè¿‡æ•°: {results['passed']}")
    logger.info(f"å¤±è´¥æ•°: {results['failed']}")
    logger.info(f"é€šè¿‡ç‡: {results['passed'] / results['total'] * 100:.1f}%" if results['total'] > 0 else "æ— æµ‹è¯•è¿è¡Œ")
    
    if results['failed'] == 0:
        logger.info("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡")
    else:
        logger.info("âš ï¸ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥æ—¥å¿—è·å–è¯¦ç»†ä¿¡æ¯")


if __name__ == "__main__":
    run_all_tests()